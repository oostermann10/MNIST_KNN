{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5514f005",
   "metadata": {},
   "source": [
    "# First assessed lab - Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8bdaea",
   "metadata": {},
   "source": [
    "Build a classifier for the MNIST dataset that achieves over 97% accuracy on the test set.\n",
    "Use the first 60000 data samples for the training set and the remaining samples for the test set.\n",
    "Hint: the *KNeighborsClassifier* works quite well for this task; you just need to find good hyperparameter values (try a grid search on the *weights* and *n_neighbors* hyperparameters).\n",
    "Show the best hyperparameter configuration obtained via cross-validation and the best validation score. Finally, test the best model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08f1e3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owenostermann/Desktop/Python_Enviroment/owenvenv/lib/python3.9/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eadd5f3",
   "metadata": {},
   "source": [
    "Now that we have the data in a desirable form that is easy to work with. We have the 28X28 pixels, or the 784 columns of pixels and the 1 target column. Within the first 784 columns we have values between 0 and 255, 0 being a white background and 255 being a completely black background in the pixel. We also have the target, or the actual number that the pixels compose. As per the questions requirments, we are to train the model on the first 60,000 units and then test it on the last 10,000 units. Let's create our training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training Data:  60000\n",
      "Length of the Testing Data:  10000\n"
     ]
    }
   ],
   "source": [
    "# up to but not including, so here we get the first 60,000 to train\n",
    "# from index 0 to 59,999\n",
    "X_train, Y_train = X[0:60000], y[0:60000]\n",
    "\n",
    "# Now we do the same for the testing set for x and y\n",
    "X_test, Y_test = X[60000:70000], y[60000:70000]\n",
    "\n",
    "# double check the lengths of the testing and training to ensure proper split\n",
    "print(\"Length of Training Data: \", len(X_train))\n",
    "print(\"Length of the Testing Data: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34537754",
   "metadata": {},
   "source": [
    "Now that we have set up the training and testing set we are ready to take our data and train it on the KNeighborsClassifier from sklearn. We will need to use a gridsearch to hyptertune for the weights and number of neighbours parameteres. Once we achive this, we will show the best hyperparameter configuration obtained via cross-validation and the best validation score.\n",
    "\n",
    "First lets use a naive approach and use square root of the number of classes as K and then see which model preforms better between weights of distance and uniform. We will then optimize these parameteres later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e17b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier # importing the model from sklearn\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# we choose our upper bound as the squre root of the number of predictors (784 pixel values)\n",
    "# but since this is even, we want k + 1\n",
    "k = int(math.sqrt(len(X[0])) + 1) \n",
    "\n",
    "# the two weight types we will try\n",
    "weights_type = [\"distance\", \"uniform\"]\n",
    "\n",
    "# now we are ready to train both of our models and test the accuracy to get a baseline\n",
    "baseline_dis = KNeighborsClassifier(n_neighbors= k, weights = weights_type[0])\n",
    "baseline_uni = KNeighborsClassifier(n_neighbors = k, weights = weights_type[1])\n",
    "baseline_dis.fit(X_train, Y_train)\n",
    "baseline_uni.fit(X_train, Y_train)\n",
    "\n",
    "# corss validation predict 3 fold\n",
    "y_train_pred_dis = cross_val_predict(baseline_dis, X_train, Y_train, cv=3)\n",
    "y_train_pred_uni = cross_val_predict(baseline_uni, X_train, Y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb1b3079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of baseline on training set (k = 29, weight = distance) =  0.9530166666666666\n",
      "Accuracy of baseline on training set (k = 29, weight = uniform) =  0.9517166666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_dis_model = accuracy_score(Y_train, y_train_pred_dis)\n",
    "acc_uni_model = accuracy_score(Y_train, y_train_pred_uni)\n",
    "\n",
    "print(\"Accuracy of baseline on training set (k = 29, weight = distance) = \", acc_dis_model)\n",
    "print(\"Accuracy of baseline on training set (k = 29, weight = uniform) = \", acc_uni_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398d1495",
   "metadata": {},
   "source": [
    "Now that we have these baselines, we can see that they are 95% ish accurate. But we want to do better. Lets use a gridsearch and cross validation method to hypertune the parameters to see if we can get our model to be even more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b859218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [3, 5, 7],\n",
       "                         &#x27;weights&#x27;: [&#x27;distance&#x27;, &#x27;uniform&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [3, 5, 7],\n",
       "                         &#x27;weights&#x27;: [&#x27;distance&#x27;, &#x27;uniform&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [3, 5, 7],\n",
       "                         'weights': ['distance', 'uniform']})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV # importing the grid search/ cross validation\n",
    "\n",
    "K_neigh = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors': [3, 5, 7], 'weights': [\"distance\", \"uniform\"]}\n",
    "grid_search = GridSearchCV(estimator= K_neigh, param_grid = parameters, cv = 5)\n",
    "grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e02c72f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypertuned K = 3\n",
      "Hypertuned Weights = distance\n",
      "Best Cross Validation Score:  0.9711166666666665\n"
     ]
    }
   ],
   "source": [
    "print(\"Hypertuned K =\", grid_search.best_params_[\"n_neighbors\"])\n",
    "print(\"Hypertuned Weights =\", grid_search.best_params_[\"weights\"])\n",
    "\n",
    "print(\"Best Cross Validation Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0361fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predicted using the best model\n",
    "y_predicted_best_model = grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b132840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy:  0.9717\n"
     ]
    }
   ],
   "source": [
    "# now evaluate the accuracy\n",
    "best_model_accuracy = accuracy_score(y_predicted_best_model, Y_test)\n",
    "print(\"Best Model Accuracy: \", best_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c9b61",
   "metadata": {},
   "source": [
    "So now we can see that the accuracy of our model has gone up from around 95% for the baselines up to 97.17% for the best model. We got a cross validation score of 97.11% and used the parameters K = 3 and weight = \"distance\". The model is successfull at predicting the handwritten digits in the MNIST dataset based on the provided pixels.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('owenvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9f3be45e5b2ad0f36abd418904c89bb8b169a6a63bcdea03d6dbd260b276c84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
